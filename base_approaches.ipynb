{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ir_datasets\n",
    "import torch\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "from deep_translator import GoogleTranslator\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from rank_bm25 import BM25Okapi\n",
    "import string\n",
    "from rank_bm25 import BM25Okapi\n",
    "import ir_measures\n",
    "from ir_measures import nDCG, MAP, RBP, Recall, Qrel, ScoredDoc\n",
    "from itertools import chain\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(id='neuclir/1/ru/trec-2023', provides=['docs', 'queries', 'qrels'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = ir_datasets.load(\"neuclir/1/ru/trec-2023\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_documents = [(doc.doc_id, doc.title, doc.text) for doc in tqdm(dataset.docs_iter())]\n",
    "english_queries = [(query.query_id, query.title) for query in dataset.queries_iter()]\n",
    "qrels = [(qrel.query_id, qrel.doc_id, qrel.relevance) for qrel in dataset.qrels_iter()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "474437e8ba1d41c9b6070b3ba6aefe67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25634 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7413a729ebdf44e6b564f01873b74e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627543 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "24871"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels_ids = {entry[1] for entry in tqdm(qrels)}\n",
    "russian_documents_subset = [doc for doc in tqdm(russian_documents) if doc[0] in qrels_ids]\n",
    "len(russian_documents_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(qrels, result):\n",
    "    qrels = [\n",
    "        Qrel(query_id=query_id, doc_id=doc_id, relevance=relevance)\n",
    "        for query_id, doc_id, relevance, iterations in qrels   \n",
    "    ]\n",
    "\n",
    "    runs = [\n",
    "        ScoredDoc(query_id=query_id, doc_id=doc_id, score=score)\n",
    "        for query_id, doc_id, score in result\n",
    "    ]\n",
    "#     scores = ir_measures.calc_aggregate([nDCG@20, MAP, RBP(rel=1), Recall@100, Recall@1000], qrels, runs)\n",
    "    scores = ir_measures.calc_aggregate([nDCG@20, MAP, Recall@100, Recall@1000], qrels, runs)\n",
    "\n",
    "\n",
    "    return scores\n",
    "    \n",
    "    \n",
    "\n",
    "def print_document(document_id):\n",
    "    print(next((doc for doc in russian_documents if doc[0] == document_id), None))\n",
    "\n",
    "\n",
    "def translate_query(query):\n",
    "    translated_text = GoogleTranslator(source='auto', target='ru').translate(query[1]) \n",
    "    translated_tuple = (query[0], translated_text)\n",
    "\n",
    "    return translated_tuple\n",
    "\n",
    "def tokenize(text):\n",
    "\n",
    "    query_tokens = text[1].split()\n",
    "\n",
    "    # Define Russian stopwords\n",
    "    russian_stopwords = set(stopwords.words('russian'))\n",
    "\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [token.translate(translator).lower() for token in query_tokens if token.lower() not in russian_stopwords]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def convert_to_score(result, qrels):\n",
    "    combined_dict = { (qid, docid): relevance for qid, docid, relevance in result}\n",
    "\n",
    "    correct_matches = 0\n",
    "    total = 0  \n",
    "\n",
    "    # Compare qrels with combined_documents\n",
    "    for qid, docid, true_relevance in qrels:\n",
    "        if (qid, docid) in combined_dict:\n",
    "            predicted_relevance = combined_dict[(qid, docid)]\n",
    "            if predicted_relevance == true_relevance:\n",
    "                correct_matches += 1\n",
    "            total += 1  \n",
    "        \n",
    "    accuracy = correct_matches / total if total > 0 else 0\n",
    "    return accuracy\n",
    "\n",
    "def combine_documents(documents):\n",
    "    combine_documents =  list(map(lambda doc: (doc[0], doc[1] + doc[2]), documents))\n",
    "    return combine_documents\n",
    "\n",
    "def assign_rank_tf_idf(value):\n",
    "    if value >= 0.1:\n",
    "        return 3\n",
    "    elif value >= 0.5:\n",
    "        return 2\n",
    "    elif value >= 0.01:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def assign_rank(value):\n",
    "    if value >= 0.2:\n",
    "        return 3\n",
    "    elif value >= 0.11:\n",
    "        return 2\n",
    "    elif value >= 0.05:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def assign_rank_bm25(value):\n",
    "    if value >= 10:\n",
    "        return 3\n",
    "    elif value >= 6:\n",
    "        return 2\n",
    "    elif value >= 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverted_index(query, documents):\n",
    "    # Translate the query, assuming this is a function you have defined elsewhere\n",
    "    translated_query = translate_query(query)\n",
    "\n",
    "    tokenized_query = tokenize(translated_query)\n",
    "\n",
    "    # Initialize a dictionary to store documents for each word\n",
    "    word_to_documents = {}\n",
    "\n",
    "    # Iterate over each word in the query\n",
    "    for word in tokenized_query:\n",
    "        # Check each document for the word\n",
    "        for doc_id, combined_text in documents:\n",
    "            # If the word is found in the combined text (case-sensitive check)\n",
    "            if word in combined_text:\n",
    "                if word not in word_to_documents:\n",
    "                    word_to_documents[word] = []\n",
    "                word_to_documents[word].append(doc_id)\n",
    "\n",
    "    # Create a dictionary to store the document frequencies (relevance score)\n",
    "    document_frequency = {doc_id: 0 for doc_id, _ in documents}\n",
    "\n",
    "    # For each word found in the documents, increment the score of the relevant documents\n",
    "    for word, docs in word_to_documents.items():\n",
    "        for doc_id in docs:\n",
    "            document_frequency[doc_id] += 1  # Increment relevance score for documents that contain the word\n",
    "\n",
    "    # Sort documents based on relevance (document frequency)\n",
    "    sorted_documents = sorted(document_frequency.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Format the final output, giving a max score of 3 if the relevance is above 3, else leave as is\n",
    "    formatted_docs = [(query[0], doc_id, min(relevance, 3)) for doc_id, relevance in sorted_documents]\n",
    "\n",
    "    return formatted_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(query, documents):\n",
    "    # Extract the query and documents texts\n",
    "    query_id, query_text = query\n",
    "    doc_ids, doc_texts = zip(*documents)  # unzip the document tuples into ids and texts\n",
    "\n",
    "    # Combine the query text with the document texts for vectorization\n",
    "    texts = [query_text] + list(doc_texts)\n",
    "\n",
    "    # Create the TF-IDF Vectorizer\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "    # Fit and transform the text data\n",
    "    tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "\n",
    "    # Extract the query vector (the first row in the matrix)\n",
    "    query_vector = tfidf_matrix[0:1]\n",
    "\n",
    "    # Compute the cosine similarity between the query vector and the document vectors\n",
    "    cosine_similarities = cosine_similarity(query_vector, tfidf_matrix[1:]).flatten()\n",
    "\n",
    "    # Pair each document id with its corresponding cosine similarity score\n",
    "    scored_documents = [(doc_id, similarity) for doc_id, similarity in zip(doc_ids, cosine_similarities)]\n",
    "\n",
    "    # Sort documents by similarity score in descending order\n",
    "    sorted_documents = sorted(scored_documents, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "\n",
    "    ranked_data = [(query_id, uuid, assign_rank(value)) for uuid, value in sorted_documents]\n",
    "\n",
    "\n",
    "    return ranked_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25(query, documents):\n",
    "    # query = english_queries[2]\n",
    "\n",
    "    # Translate the query (assumed to return a tuple with the query number and tokens)\n",
    "    translated_query = translate_query(query)\n",
    "\n",
    "    query_number = translated_query[0]  \n",
    "    query_tokens = tokenize(translated_query) \n",
    "    document_ids = [item[0] for item in documents] \n",
    "\n",
    "    # Tokenize documents and initialize BM25\n",
    "    corpus = [tokenize(doc) for doc in documents]\n",
    "    bm25 = BM25Okapi(corpus)\n",
    "\n",
    "    # Get BM25 scores for the query tokens\n",
    "    scores = bm25.get_scores(query_tokens)\n",
    "\n",
    "    # Combine query_number, document_ids, and scores into the required format\n",
    "    scored_documents = [(doc_id, score) for doc_id, score in zip(document_ids, scores)]\n",
    "\n",
    "    sorted_documents = sorted(scored_documents, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    ranked_data = [(query_number, uuid, assign_rank_bm25(value)) for uuid, value in sorted_documents]\n",
    "\n",
    "\n",
    "    return ranked_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_documents = combine_documents(russian_documents_subset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('200', 'Corruption Bribery Sports Federation Olympics')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_queries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbba179883d64d678151f3305ebc3d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_ranked_documents_inverted_index = []\n",
    "for query in tqdm(english_queries):\n",
    "    scores_inverted_index = inverted_index(query, combined_documents)\n",
    "    all_ranked_documents_inverted_index.append(scores_inverted_index)\n",
    "\n",
    "flat_list_inverted_index = list(chain.from_iterable(all_ranked_documents_inverted_index))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{R@1000: 0.5265270604239012,\n",
       " AP: 0.07992448263972612,\n",
       " R@100: 0.19601926707180986,\n",
       " nDCG@20: 0.12663033443370092}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(qrels, flat_list_inverted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__name__': 'ir_measures.providers', '__doc__': None, '__package__': 'ir_measures.providers', '__loader__': <_frozen_importlib_external.SourceFileLoader object at 0x000001B7028A59D0>, '__spec__': ModuleSpec(name='ir_measures.providers', loader=<_frozen_importlib_external.SourceFileLoader object at 0x000001B7028A59D0>, origin='c:\\\\Users\\\\I555270\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\ir_measures\\\\providers\\\\__init__.py', submodule_search_locations=['c:\\\\Users\\\\I555270\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\ir_measures\\\\providers']), '__path__': ['c:\\\\Users\\\\I555270\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\ir_measures\\\\providers'], '__file__': 'c:\\\\Users\\\\I555270\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\ir_measures\\\\providers\\\\__init__.py', '__cached__': 'c:\\\\Users\\\\I555270\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\ir_measures\\\\providers\\\\__pycache__\\\\__init__.cpython-311.pyc', '__builtins__': {'__name__': 'builtins', '__doc__': \"Built-in functions, exceptions, and other objects.\\n\\nNoteworthy: None is the `nil' object; Ellipsis represents `...' in slices.\", '__package__': '', '__loader__': <class '_frozen_importlib.BuiltinImporter'>, '__spec__': ModuleSpec(name='builtins', loader=<class '_frozen_importlib.BuiltinImporter'>, origin='built-in'), '__build_class__': <built-in function __build_class__>, '__import__': <built-in function __import__>, 'abs': <built-in function abs>, 'all': <built-in function all>, 'any': <built-in function any>, 'ascii': <built-in function ascii>, 'bin': <built-in function bin>, 'breakpoint': <built-in function breakpoint>, 'callable': <built-in function callable>, 'chr': <built-in function chr>, 'compile': <built-in function compile>, 'delattr': <built-in function delattr>, 'dir': <built-in function dir>, 'divmod': <built-in function divmod>, 'eval': <built-in function eval>, 'exec': <built-in function exec>, 'format': <built-in function format>, 'getattr': <built-in function getattr>, 'globals': <built-in function globals>, 'hasattr': <built-in function hasattr>, 'hash': <built-in function hash>, 'hex': <built-in function hex>, 'id': <built-in function id>, 'input': <bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x000001B314D33350>>, 'isinstance': <built-in function isinstance>, 'issubclass': <built-in function issubclass>, 'iter': <built-in function iter>, 'aiter': <built-in function aiter>, 'len': <built-in function len>, 'locals': <built-in function locals>, 'max': <built-in function max>, 'min': <built-in function min>, 'next': <built-in function next>, 'anext': <built-in function anext>, 'oct': <built-in function oct>, 'ord': <built-in function ord>, 'pow': <built-in function pow>, 'print': <built-in function print>, 'repr': <built-in function repr>, 'round': <built-in function round>, 'setattr': <built-in function setattr>, 'sorted': <built-in function sorted>, 'sum': <built-in function sum>, 'vars': <built-in function vars>, 'None': None, 'Ellipsis': Ellipsis, 'NotImplemented': NotImplemented, 'False': False, 'True': True, 'bool': <class 'bool'>, 'memoryview': <class 'memoryview'>, 'bytearray': <class 'bytearray'>, 'bytes': <class 'bytes'>, 'classmethod': <class 'classmethod'>, 'complex': <class 'complex'>, 'dict': <class 'dict'>, 'enumerate': <class 'enumerate'>, 'filter': <class 'filter'>, 'float': <class 'float'>, 'frozenset': <class 'frozenset'>, 'property': <class 'property'>, 'int': <class 'int'>, 'list': <class 'list'>, 'map': <class 'map'>, 'object': <class 'object'>, 'range': <class 'range'>, 'reversed': <class 'reversed'>, 'set': <class 'set'>, 'slice': <class 'slice'>, 'staticmethod': <class 'staticmethod'>, 'str': <class 'str'>, 'super': <class 'super'>, 'tuple': <class 'tuple'>, 'type': <class 'type'>, 'zip': <class 'zip'>, '__debug__': True, 'BaseException': <class 'BaseException'>, 'BaseExceptionGroup': <class 'BaseExceptionGroup'>, 'Exception': <class 'Exception'>, 'GeneratorExit': <class 'GeneratorExit'>, 'KeyboardInterrupt': <class 'KeyboardInterrupt'>, 'SystemExit': <class 'SystemExit'>, 'ArithmeticError': <class 'ArithmeticError'>, 'AssertionError': <class 'AssertionError'>, 'AttributeError': <class 'AttributeError'>, 'BufferError': <class 'BufferError'>, 'EOFError': <class 'EOFError'>, 'ImportError': <class 'ImportError'>, 'LookupError': <class 'LookupError'>, 'MemoryError': <class 'MemoryError'>, 'NameError': <class 'NameError'>, 'OSError': <class 'OSError'>, 'ReferenceError': <class 'ReferenceError'>, 'RuntimeError': <class 'RuntimeError'>, 'StopAsyncIteration': <class 'StopAsyncIteration'>, 'StopIteration': <class 'StopIteration'>, 'SyntaxError': <class 'SyntaxError'>, 'SystemError': <class 'SystemError'>, 'TypeError': <class 'TypeError'>, 'ValueError': <class 'ValueError'>, 'Warning': <class 'Warning'>, 'FloatingPointError': <class 'FloatingPointError'>, 'OverflowError': <class 'OverflowError'>, 'ZeroDivisionError': <class 'ZeroDivisionError'>, 'BytesWarning': <class 'BytesWarning'>, 'DeprecationWarning': <class 'DeprecationWarning'>, 'EncodingWarning': <class 'EncodingWarning'>, 'FutureWarning': <class 'FutureWarning'>, 'ImportWarning': <class 'ImportWarning'>, 'PendingDeprecationWarning': <class 'PendingDeprecationWarning'>, 'ResourceWarning': <class 'ResourceWarning'>, 'RuntimeWarning': <class 'RuntimeWarning'>, 'SyntaxWarning': <class 'SyntaxWarning'>, 'UnicodeWarning': <class 'UnicodeWarning'>, 'UserWarning': <class 'UserWarning'>, 'BlockingIOError': <class 'BlockingIOError'>, 'ChildProcessError': <class 'ChildProcessError'>, 'ConnectionError': <class 'ConnectionError'>, 'FileExistsError': <class 'FileExistsError'>, 'FileNotFoundError': <class 'FileNotFoundError'>, 'InterruptedError': <class 'InterruptedError'>, 'IsADirectoryError': <class 'IsADirectoryError'>, 'NotADirectoryError': <class 'NotADirectoryError'>, 'PermissionError': <class 'PermissionError'>, 'ProcessLookupError': <class 'ProcessLookupError'>, 'TimeoutError': <class 'TimeoutError'>, 'IndentationError': <class 'IndentationError'>, 'IndexError': <class 'IndexError'>, 'KeyError': <class 'KeyError'>, 'ModuleNotFoundError': <class 'ModuleNotFoundError'>, 'NotImplementedError': <class 'NotImplementedError'>, 'RecursionError': <class 'RecursionError'>, 'UnboundLocalError': <class 'UnboundLocalError'>, 'UnicodeError': <class 'UnicodeError'>, 'BrokenPipeError': <class 'BrokenPipeError'>, 'ConnectionAbortedError': <class 'ConnectionAbortedError'>, 'ConnectionRefusedError': <class 'ConnectionRefusedError'>, 'ConnectionResetError': <class 'ConnectionResetError'>, 'TabError': <class 'TabError'>, 'UnicodeDecodeError': <class 'UnicodeDecodeError'>, 'UnicodeEncodeError': <class 'UnicodeEncodeError'>, 'UnicodeTranslateError': <class 'UnicodeTranslateError'>, 'ExceptionGroup': <class 'ExceptionGroup'>, 'EnvironmentError': <class 'OSError'>, 'IOError': <class 'OSError'>, 'WindowsError': <class 'OSError'>, 'open': <built-in function open>, 'copyright': Copyright (c) 2001-2023 Python Software Foundation.\n",
      "All Rights Reserved.\n",
      "\n",
      "Copyright (c) 2000 BeOpen.com.\n",
      "All Rights Reserved.\n",
      "\n",
      "Copyright (c) 1995-2001 Corporation for National Research Initiatives.\n",
      "All Rights Reserved.\n",
      "\n",
      "Copyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.\n",
      "All Rights Reserved., 'credits':     Thanks to CWI, CNRI, BeOpen.com, Zope Corporation and a cast of thousands\n",
      "    for supporting Python development.  See www.python.org for more information., 'license': Type license() to see the full license text, 'help': Type help() for interactive help, or help(object) for help about object., 'execfile': <function execfile at 0x000001B3138EEE80>, 'runfile': <function runfile at 0x000001B313A842C0>, '__IPYTHON__': True, 'display': <function display at 0x000001B31223B6A0>, '__pybind11_internals_v4_msvc__': <capsule object NULL at 0x000001B323C70FC0>, '__pybind11_internals_v4_mingw_libstdcpp_cxxabi1014__': <capsule object NULL at 0x000001B3392868B0>, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x000001B314D40690>>}, 'registry': {'accuracy': <ir_measures.providers.accuracy_provider.AccuracyProvider object at 0x000001B7AB500D50>, 'compat': <ir_measures.providers.compat_provider.CompatProvider object at 0x000001B7AB5015D0>, 'cwl_eval': <ir_measures.providers.cwl_eval.CwlEvalProvider object at 0x000001B7AB503710>, 'pyndeval': <ir_measures.providers.pyndeval_provider.PyNdEvalProvider object at 0x000001B7AB518C90>, 'pytrec_eval': <ir_measures.providers.pytrec_eval_provider.PytrecEvalProvider object at 0x000001B7AB51A910>, 'judged': <ir_measures.providers.judged_provider.JudgedProvider object at 0x000001B7AB51ADD0>, 'gdeval': <ir_measures.providers.gdeval_provider.GdevalProvider object at 0x000001B7AB51B4D0>, 'trectools': <ir_measures.providers.trectools_provider.TrectoolsProvider object at 0x000001B7AB5287D0>, 'msmarco': <ir_measures.providers.msmarco_provider.MsMarcoProvider object at 0x000001B7AB528DD0>, 'ranx': <ir_measures.providers.ranx_provider.RanxProvider object at 0x000001B7AB548990>, 'runtime': <ir_measures.providers.runtime_provider.RuntimeProvider object at 0x000001B7AB549150>}, 'register': <function register at 0x000001B7AB2DCE00>, 'base': <module 'ir_measures.providers.base' from 'c:\\\\Users\\\\I555270\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\ir_measures\\\\providers\\\\base.py'>, 'Provider': <class 'ir_measures.providers.base.Provider'>, 'Evaluator': <class 'ir_measures.providers.base.Evaluator'>, 'accuracy_provider': <module 'ir_measures.providers.accuracy_provider' from 'c:\\\\Users\\\\I555270\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\ir_measures\\\\providers\\\\accuracy_provider.py'>, 'AccuracyProvider': <class 'ir_measures.providers.accuracy_provider.AccuracyProvider'>, 'fallback_provider': <module 'ir_measures.providers.fallback_provider' from 'c:\\\\Users\\\\I555270\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\ir_measures\\\\providers\\\\fallback_provider.py'>, 'FallbackProvider': <class 'ir_measures.providers.fallback_provider.FallbackProvider'>, 'compat_provider': <module 'ir_measures.providers.compat_provider' from 'c:\\\\Users\\\\I555270\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\ir_measures\\\\providers\\\\compat_provider.py'>, 'CompatProvider': <class 'ir_measures.providers.compat_provider.CompatProvider'>, 'cwl_eval': <module 'ir_measures.providers.cwl_eval' from 'c:\\\\Users\\\\I555270\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\ir_measures\\\\providers\\\\cwl_eval.py'>, 'CwlEvalProvider': <class 'ir_measures.providers.cwl_eval.CwlEvalProvider'>, 'CwlMetric': <class 'ir_measures.providers.cwl_eval.CwlMetric'>, 'pyndeval_provider': <module 'ir_measures.providers.pyndeval_provider' from 'c:\\\\Users\\\\I555270\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\ir_measures\\\\providers\\\\pyndeval_provider.py'>, 'PyNdEvalProvider': <class 'ir_measures.providers.pyndeval_provider.PyNdEvalProvider'>, 'pytrec_eval_provider': <module 'ir_measures.providers.pytrec_eval_provider' from 'c:\\\\Users\\\\I555270\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\ir_measures\\\\providers\\\\pytrec_eval_provider.py'>, 'PytrecEvalProvider': <class 'ir_measures.providers.pytrec_eval_provider.PytrecEvalProvider'>, 'judged_provider': <module 'ir_measures.providers.judged_provider' from 'c:\\\\Users\\\\I555270\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\ir_measures\\\\providers\\\\judged_provider.py'>, 'JudgedProvider': <class 'ir_measures.providers.judged_provider.JudgedProvider'>, 'gdeval_provider': <module 'ir_measures.providers.gdeval_provider' from 'c:\\\\Users\\\\I555270\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\ir_measures\\\\providers\\\\gdeval_provider.py'>, 'GdevalProvider': <class 'ir_measures.providers.gdeval_provider.GdevalProvider'>, 'trectools_provider': <module 'ir_measures.providers.trectools_provider' from 'c:\\\\Users\\\\I555270\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\ir_measures\\\\providers\\\\trectools_provider.py'>, 'TrectoolsProvider': <class 'ir_measures.providers.trectools_provider.TrectoolsProvider'>, 'msmarco_provider': <module 'ir_measures.providers.msmarco_provider' from 'c:\\\\Users\\\\I555270\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\ir_measures\\\\providers\\\\msmarco_provider.py'>, 'MsMarcoProvider': <class 'ir_measures.providers.msmarco_provider.MsMarcoProvider'>, 'ranx_provider': <module 'ir_measures.providers.ranx_provider' from 'c:\\\\Users\\\\I555270\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\ir_measures\\\\providers\\\\ranx_provider.py'>, 'RanxProvider': <class 'ir_measures.providers.ranx_provider.RanxProvider'>, 'runtime_provider': <module 'ir_measures.providers.runtime_provider' from 'c:\\\\Users\\\\I555270\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\ir_measures\\\\providers\\\\runtime_provider.py'>, 'RuntimeProvider': <class 'ir_measures.providers.runtime_provider.RuntimeProvider'>, 'define': <function define at 0x000001B7AB51C2C0>, 'define_byquery': <function define_byquery at 0x000001B7AB541620>}\n"
     ]
    }
   ],
   "source": [
    "print(ir_measures.providers.__dict__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fff14489c3d1413b930a7fd3b96af04f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[136], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m all_ranked_documents_tfidf \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m tqdm(english_queries):\n\u001b[1;32m----> 3\u001b[0m     scores_tfidf \u001b[38;5;241m=\u001b[39m \u001b[43mtf_idf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombined_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     all_ranked_documents\u001b[38;5;241m.\u001b[39mappend(scores_tfidf)\n\u001b[0;32m      6\u001b[0m flat_list_tfidf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chain\u001b[38;5;241m.\u001b[39mfrom_iterable(all_ranked_documents))\n",
      "Cell \u001b[1;32mIn[7], line 13\u001b[0m, in \u001b[0;36mtf_idf\u001b[1;34m(query, documents)\u001b[0m\n\u001b[0;32m     10\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer(stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Fit and transform the text data\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m tfidf_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Extract the query vector (the first row in the matrix)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m query_vector \u001b[38;5;241m=\u001b[39m tfidf_matrix[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\I555270\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:2133\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[0;32m   2127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2128\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[0;32m   2129\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[0;32m   2130\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[0;32m   2131\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[0;32m   2132\u001b[0m )\n\u001b[1;32m-> 2133\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m   2135\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2136\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\I555270\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1388\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1380\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1381\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1382\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1383\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1384\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1385\u001b[0m             )\n\u001b[0;32m   1386\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1391\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\I555270\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1275\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1273\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[0;32m   1274\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m-> 1275\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1276\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1277\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[1;32mc:\\Users\\I555270\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:116\u001b[0m, in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ngrams \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stop_words \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 116\u001b[0m         doc \u001b[38;5;241m=\u001b[39m \u001b[43mngrams\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_words\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m         doc \u001b[38;5;241m=\u001b[39m ngrams(doc)\n",
      "File \u001b[1;32mc:\\Users\\I555270\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:245\u001b[0m, in \u001b[0;36m_VectorizerMixin._word_ngrams\u001b[1;34m(self, tokens, stop_words)\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    240\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.nan is an invalid document, expected byte or unicode string.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    241\u001b[0m         )\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m doc\n\u001b[1;32m--> 245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_word_ngrams\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokens, stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    246\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Turn tokens into a sequence of n-grams after stop words filtering\"\"\"\u001b[39;00m\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;66;03m# handle stop words\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_ranked_documents_tfidf = []\n",
    "for query in tqdm(english_queries):\n",
    "    scores_tfidf = tf_idf(query, combined_documents)\n",
    "    all_ranked_documents_tfidf.append(scores_tfidf)\n",
    "\n",
    "flat_list_tfidf = list(chain.from_iterable(all_ranked_documents_tfidf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flat_list_tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[134], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m evaluate(qrels, \u001b[43mflat_list_tfidf\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'flat_list_tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "evaluate(qrels, flat_list_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f5eaa643f684672a0318721d3dff39a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dff619b3e1441788d76e0e7b8e7a399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24871 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[137], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m all_ranked_documents_bm25 \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m tqdm(english_queries):\n\u001b[1;32m----> 3\u001b[0m     scores_bm25 \u001b[38;5;241m=\u001b[39m \u001b[43mbm25\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombined_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     all_ranked_documents_bm25\u001b[38;5;241m.\u001b[39mappend(scores_bm25)\n\u001b[0;32m      6\u001b[0m flat_list_bm25 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chain\u001b[38;5;241m.\u001b[39mfrom_iterable(all_ranked_documents_bm25))\n",
      "Cell \u001b[1;32mIn[102], line 12\u001b[0m, in \u001b[0;36mbm25\u001b[1;34m(query, documents)\u001b[0m\n\u001b[0;32m      9\u001b[0m document_ids \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m documents] \n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Tokenize documents and initialize BM25\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     13\u001b[0m bm25 \u001b[38;5;241m=\u001b[39m BM25Okapi(corpus)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Get BM25 scores for the query tokens\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[102], line 12\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      9\u001b[0m document_ids \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m documents] \n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Tokenize documents and initialize BM25\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m corpus \u001b[38;5;241m=\u001b[39m [\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m tqdm(documents)]\n\u001b[0;32m     13\u001b[0m bm25 \u001b[38;5;241m=\u001b[39m BM25Okapi(corpus)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Get BM25 scores for the query tokens\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[132], line 34\u001b[0m, in \u001b[0;36mtokenize\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     31\u001b[0m query_tokens \u001b[38;5;241m=\u001b[39m text[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit()\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Define Russian stopwords\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m russian_stopwords \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[43mstopwords\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwords\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrussian\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     36\u001b[0m translator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m.\u001b[39mmaketrans(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, string\u001b[38;5;241m.\u001b[39mpunctuation)\n\u001b[0;32m     37\u001b[0m tokens \u001b[38;5;241m=\u001b[39m [token\u001b[38;5;241m.\u001b[39mtranslate(translator)\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m query_tokens \u001b[38;5;28;01mif\u001b[39;00m token\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m russian_stopwords]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nltk\\corpus\\reader\\wordlist.py:21\u001b[0m, in \u001b[0;36mWordListCorpusReader.words\u001b[1;34m(self, fileids, ignore_lines_startswith)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwords\u001b[39m(\u001b[38;5;28mself\u001b[39m, fileids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ignore_lines_startswith\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m     20\u001b[0m         line\n\u001b[1;32m---> 21\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m line_tokenize(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileids\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line\u001b[38;5;241m.\u001b[39mstartswith(ignore_lines_startswith)\n\u001b[0;32m     23\u001b[0m     ]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nltk\\corpus\\reader\\api.py:218\u001b[0m, in \u001b[0;36mCorpusReader.raw\u001b[1;34m(self, fileids)\u001b[0m\n\u001b[0;32m    216\u001b[0m contents \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fileids:\n\u001b[1;32m--> 218\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m    219\u001b[0m         contents\u001b[38;5;241m.\u001b[39mappend(fp\u001b[38;5;241m.\u001b[39mread())\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concat(contents)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nltk\\corpus\\reader\\api.py:231\u001b[0m, in \u001b[0;36mCorpusReader.open\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;124;03mReturn an open stream that can be used to read the given file.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;124;03mIf the file's encoding is not None, then the stream will\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;124;03m:param file: The file identifier of the file to read.\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    230\u001b[0m encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding(file)\n\u001b[1;32m--> 231\u001b[0m stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_root\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mopen(encoding)\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stream\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nltk\\data.py:334\u001b[0m, in \u001b[0;36mFileSystemPathPointer.join\u001b[1;34m(self, fileid)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjoin\u001b[39m(\u001b[38;5;28mself\u001b[39m, fileid):\n\u001b[0;32m    333\u001b[0m     _path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path, fileid)\n\u001b[1;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFileSystemPathPointer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nltk\\compat.py:41\u001b[0m, in \u001b[0;36mpy3_data.<locals>._decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decorator\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     40\u001b[0m     args \u001b[38;5;241m=\u001b[39m (args[\u001b[38;5;241m0\u001b[39m], add_py3_data(args[\u001b[38;5;241m1\u001b[39m])) \u001b[38;5;241m+\u001b[39m args[\u001b[38;5;241m2\u001b[39m:]\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minit_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nltk\\data.py:311\u001b[0m, in \u001b[0;36mFileSystemPathPointer.__init__\u001b[1;34m(self, _path)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;124;03mCreate a new path pointer for the given absolute path.\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \n\u001b[0;32m    307\u001b[0m \u001b[38;5;124;03m:raise IOError: If the given path does not exist.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    310\u001b[0m _path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(_path)\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m _path)\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path \u001b[38;5;241m=\u001b[39m _path\n",
      "File \u001b[1;32m<frozen genericpath>:19\u001b[0m, in \u001b[0;36mexists\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_ranked_documents_bm25 = []\n",
    "for query in tqdm(english_queries):\n",
    "    scores_bm25 = bm25(query, combined_documents)\n",
    "    all_ranked_documents_bm25.append(scores_bm25)\n",
    "\n",
    "flat_list_bm25 = list(chain.from_iterable(all_ranked_documents_bm25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[140], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m evaluate(qrels, flat_list)\n",
      "File \u001b[1;32mc:\\Users\\I555270\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\displayhook.py:264\u001b[0m, in \u001b[0;36mDisplayHook.__call__\u001b[1;34m(self, result)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, result\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    259\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Printing with history cache management.\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \n\u001b[0;32m    261\u001b[0m \u001b[38;5;124;03m    This is invoked every time the interpreter needs to print, and is\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;124;03m    activated by setting the variable sys.displayhook to it.\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 264\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_for_underscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquiet():\n\u001b[0;32m    266\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_displayhook()\n",
      "File \u001b[1;32mc:\\Users\\I555270\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\displayhook.py:70\u001b[0m, in \u001b[0;36mDisplayHook.check_for_underscore\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39mexecution_count\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m#-------------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Methods used in __call__. Override these methods to modify the behavior\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# of the displayhook.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m#-------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_for_underscore\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     71\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check if the user has set the '_' variable by hand.\"\"\"\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;66;03m# If something injected a '_' variable in __builtin__, delete\u001b[39;00m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;66;03m# ipython's automatic one so we don't clobber that.  gettext() in\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;66;03m# particular uses _, so we need to stay away from it.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluate(qrels, flat_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
